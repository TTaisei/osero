{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[データ集め](#データ集め)**\n",
    "- **[学習部分](#学習部分)**\n",
    "    - [ニューラルネットワーク](#ニューラルネットワーク)\n",
    "    - [パラメータ](#パラメータ)\n",
    "    - [データセット](#データセット)\n",
    "    - [各手法](#各手法)\n",
    "    - [学習開始](#学習開始)\n",
    "    - [グラフ作成](#グラフ作成)\n",
    "    - [精度確認](#精度確認)\n",
    "- **[モデル保存](#モデル保存)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ集め"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from osero_learn import learn\n",
    "from BitBoard import osero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAY_WAY = deepcopy(osero.PLAY_WAY)\n",
    "del PLAY_WAY[\"human\"]\n",
    "PLAY_WAY = PLAY_WAY.values()\n",
    "\n",
    "eva = [1 for i in range(64)]\n",
    "\n",
    "eva_custom = [\n",
    "     1.0, -0.6,  0.6,  0.4,  0.4,  0.6, -0.6,  1.0,\n",
    "    -0.6, -0.8,  0.0,  0.0,  0.0,  0.0, -0.8, -0.6,\n",
    "     0.6,  0.0,  0.8,  0.6,  0.6,  0.8,  0.0,  0.6,\n",
    "     0.4,  0.0,  0.6,  0.0,  0.0,  0.6,  0.0,  0.4,\n",
    "     0.4,  0.0,  0.6,  0.0,  0.0,  0.6,  0.0,  0.4,\n",
    "     0.6,  0.0,  0.8,  0.6,  0.6,  0.8,  0.0,  0.6,\n",
    "    -0.6, -0.8,  0.0,  0.0,  0.0,  0.0, -0.8, -0.6,\n",
    "     1.0, -0.6,  0.6,  0.4,  0.4,  0.6, -0.6,  1.0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "result = []\n",
    "\n",
    "turn_vari = [i for i in range(1, 61)]\n",
    "run = learn(0, 0, check_point=turn_vari, eva=[0, 0])\n",
    "i = 1\n",
    "\n",
    "for black in PLAY_WAY:\n",
    "    print(\"\\r%d/%d\" % (i, len(PLAY_WAY)), end=\"\")\n",
    "    for white in PLAY_WAY:\n",
    "        run.setup()\n",
    "        run.black_method = black\n",
    "        run.white_method = white\n",
    "        if black == osero.PLAY_WAY[\"nhand\"]:\n",
    "            run.eva[1] = eva\n",
    "        elif black == osero.PLAY_WAY[\"nhand_custom\"]:\n",
    "            run.eva[1] = eva_custom\n",
    "        if white == osero.PLAY_WAY[\"nhand\"]:\n",
    "            run.eva[0] = eva\n",
    "        elif white == osero.PLAY_WAY[\"nhand_custom\"]:\n",
    "            run.eva[0] = eva_custom\n",
    "        data_ele , result_ele = run.play()\n",
    "        for data_each_turn in data_ele:\n",
    "            data.append(data_each_turn)\n",
    "        for result_each_turn in result_ele:\n",
    "            result.append(result_each_turn)\n",
    "    i += 1\n",
    "\n",
    "data = np.array(data).astype(np.float32)\n",
    "result = np.array(result).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.datasets import TupleDataset\n",
    "from chainer.datasets import split_dataset_random\n",
    "from chainer.iterators import SerialIterator\n",
    "\n",
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "\n",
    "from chainer import optimizers\n",
    "from chainer.optimizer_hooks import GradientHardClipping\n",
    "\n",
    "from chainer.dataset import concat_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        n_in = 192\n",
    "        n_hidden = 192\n",
    "        n_out = 1\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(n_in, n_hidden)\n",
    "            self.l2 = L.Linear(n_hidden, n_hidden)\n",
    "            self.l3 = L.Linear(n_hidden, n_hidden)\n",
    "            self.l4 = L.Linear(n_hidden, n_hidden)\n",
    "            self.l5 = L.Linear(n_hidden, n_hidden)\n",
    "            self.l6 = L.Linear(n_hidden, n_hidden)\n",
    "            self.l7 = L.Linear(n_hidden, n_hidden)\n",
    "            self.l8 = L.Linear(n_hidden, n_hidden)\n",
    "            self.l9 = L.Linear(n_hidden, n_hidden)\n",
    "            self.l10 = L.Linear(n_hidden, n_out)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = 2 * F.tanh(self.l1(x))\n",
    "        h = 2 * F.tanh(self.l2(h))\n",
    "        h = 2 * F.tanh(self.l3(h))\n",
    "        h = 2 * F.tanh(self.l4(h))\n",
    "        h = 2 * F.tanh(self.l5(h))\n",
    "        h = 2 * F.tanh(self.l6(h))\n",
    "        h = 2 * F.tanh(self.l7(h))\n",
    "        h = 2 * F.tanh(self.l8(h))\n",
    "        h = 2 * F.tanh(self.l9(h))\n",
    "        h = self.l10(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "bound = 2\n",
    "n_epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TupleDataset(data, result)\n",
    "\n",
    "train_val, test = split_dataset_random(dataset, int(len(dataset) * 0.7), seed=0)\n",
    "train, valid = split_dataset_random(train_val, int(len(train_val) * 0.7), seed=0)\n",
    "\n",
    "train_iter = SerialIterator(train, batch_size=batch_size, repeat=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "optimizer = optimizers.AdaBound()\n",
    "optimizer.setup(net)\n",
    "\n",
    "for param in net.params():\n",
    "    if param.name != \"b\":\n",
    "        param.update_rule.add_hook(GradientHardClipping(-bound, bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100"
     ]
    }
   ],
   "source": [
    "results_train = {\n",
    "    \"MSE\": [],\n",
    "    \"MAE\": []\n",
    "}\n",
    "results_valid = {\n",
    "    \"MSE\": [],\n",
    "    \"MAE\": []\n",
    "}\n",
    "\n",
    "train_iter.reset()\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print(\"\\r%d/%d\" % (epoch + 1, n_epoch), end=\"\")\n",
    "    while True:\n",
    "        train_batch = train_iter.next()\n",
    "\n",
    "        x_train, t_train = concat_examples(train_batch)\n",
    "\n",
    "        y_train = net(x_train)\n",
    "        MSE_train = F.mean_squared_error(y_train, t_train)\n",
    "        MAE_train = F.mean_absolute_error(y_train, t_train)\n",
    "\n",
    "        net.cleargrads()\n",
    "        MSE_train.backward()\n",
    "\n",
    "        optimizer.update()\n",
    "\n",
    "        if train_iter.is_new_epoch:\n",
    "            with chainer.using_config(\"train\", False), chainer.using_config(\"enable_backprop\", False):\n",
    "                x_valid, t_valid = concat_examples(valid)\n",
    "                y_valid = net(x_valid)\n",
    "                MSE_valid = F.mean_squared_error(y_valid, t_valid)\n",
    "                MAE_valid = F.mean_absolute_error(y_valid, t_valid)\n",
    "\n",
    "            results_train[\"MSE\"].append(MSE_train.array)\n",
    "            results_train[\"MAE\"].append(MAE_train.array)\n",
    "            results_valid[\"MSE\"].append(MSE_valid.array)\n",
    "            results_valid[\"MAE\"].append(MAE_valid.array)\n",
    "\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グラフ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def two_plot(y, xlabel, ylabel, title, save_dir):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.plot(y[0], label=\"train\")\n",
    "    plt.plot(y[1], label=\"valid\")\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(which=\"major\")\n",
    "    plt.grid(which=\"minor\", linestyle=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.savefig(save_dir + \"/\" + title)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_plot(\n",
    "    [results_train[\"MSE\"], results_valid[\"MSE\"]],\n",
    "    \"epoch\",\n",
    "    \"mean squared error\",\n",
    "    \"mean squared error each epoch\",\n",
    "    \"fig/model_test\"\n",
    ")\n",
    "\n",
    "two_plot(\n",
    "    [results_train[\"MAE\"], results_valid[\"MAE\"]],\n",
    "    \"epoch\",\n",
    "    \"mean absolute error\",\n",
    "    \"mean absolute error each epoch\",\n",
    "    \"fig/model_test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精度確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE: 220.4348\n",
      "test MAE: 10.8649\n"
     ]
    }
   ],
   "source": [
    "x_test, t_test = concat_examples(test)\n",
    "\n",
    "with chainer.using_config(\"train\", False), chainer.using_config(\"enable_backprop\", False):\n",
    "    y_test = net(x_test)\n",
    "    MSE_test = F.mean_squared_error(y_test, t_test)\n",
    "    MAE_test = F.mean_absolute_error(y_test, t_test)\n",
    "\n",
    "print(\"test MSE: {:.4f}\".format(MSE_test.array))\n",
    "print(\"test MAE: {:.4f}\".format(MAE_test.array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chainer.serializers.save_npz(\"deep_AI.net\", net)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "400b3448902b2aa85e7a3848e7bd72dda1a711f8af9f184efc41490bde870126"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
