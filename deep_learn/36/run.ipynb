{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[準備](#準備)**\n",
    "- **[実験](#実験)**\n",
    "    - [データ量](#データ量)\n",
    "    - [バッチサイズ](#バッチサイズ)\n",
    "    - [活性化関数の乗数](#活性化関数の乗数)\n",
    "    - [最適化関数](#最適化関数)\n",
    "    - [bound](#bound)\n",
    "    - [更新回数](#更新回数)\n",
    "    - [調査ターン](#調査ターン)\n",
    "    - [重み減衰](#重み減衰)\n",
    "- **[GradientLARSの引数](#GradientLARSの引数)**\n",
    "    - [threashold](#threashold)\n",
    "    - [weight_decay](#weight_decay)\n",
    "    - [eps](#eps)\n",
    "    - [更新回数](#更新回数)\n",
    "- **[総合実験](#総合実験)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_learn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3"
     ]
    }
   ],
   "source": [
    "run = deep_learn()\n",
    "\n",
    "num_arr = [1, 5, 10]\n",
    "run.save_dir = \"fig/data_quantity\"\n",
    "i = 1\n",
    "MSE_test = []\n",
    "MAE_test = []\n",
    "\n",
    "for num in num_arr:\n",
    "    print(\"\\r%d/%d\" % (i, len(num_arr)), end=\"\")\n",
    "    run.num = num\n",
    "    run.fig_name1 = \"MSE of each epoch (data quantity is %d)\" % num\n",
    "    run.fig_name2 = \"MAE of each epoch (data quantity is %d)\" % num\n",
    "    run.set_data()\n",
    "    run.fit()\n",
    "    run.plot()\n",
    "    test_error = run.cal_test_error()\n",
    "    MSE_test.append(test_error[0])\n",
    "    MAE_test.append(test_error[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number:  [1, 5, 10]\n",
      "MSE:  [variable(318.2084), variable(184.82645), variable(302.7841)]\n",
      "MAE:  [variable(11.776607), variable(9.148406), variable(12.213117)]\n"
     ]
    }
   ],
   "source": [
    "print(\"number: \", num_arr)\n",
    "print(\"MSE: \", MSE_test)\n",
    "print(\"MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5"
     ]
    }
   ],
   "source": [
    "run = deep_learn()\n",
    "\n",
    "batch_arr = [100, 150, 200, 250, 300]\n",
    "run.save_dir = \"fig/batch_size\"\n",
    "i = 1\n",
    "MSE_test = []\n",
    "MAE_test = []\n",
    "\n",
    "run.set_data()\n",
    "\n",
    "for batch_size in batch_arr:\n",
    "    print(\"\\r%d/%d\" % (i, len(batch_arr)), end=\"\")\n",
    "    run.batch_size = batch_size\n",
    "    run.fig_name1 = \"MSE of each epoch (batch size is %d)\" % batch_size\n",
    "    run.fig_name2 = \"MAE of each epoch (batch size is %d)\" % batch_size\n",
    "    run.fit()\n",
    "    run.plot()\n",
    "    test_error = run.cal_test_error()\n",
    "    MSE_test.append(test_error[0])\n",
    "    MAE_test.append(test_error[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  [100, 150, 200, 250, 300]\n",
      "MSE:  [variable(208.28833), variable(237.04642), variable(208.90796), variable(231.01593), variable(377.63495)]\n",
      "MAE:  [variable(10.089901), variable(10.971919), variable(9.383556), variable(10.808541), variable(14.816)]\n"
     ]
    }
   ],
   "source": [
    "print(\"batch size: \", batch_arr)\n",
    "print(\"MSE: \", MSE_test)\n",
    "print(\"MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 活性化関数の乗数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6"
     ]
    }
   ],
   "source": [
    "import Net\n",
    "\n",
    "run = deep_learn()\n",
    "\n",
    "multi_arr = [1, 1.5, 2, 2.5, 3, 4]\n",
    "run.save_dir = \"fig/n_multi\"\n",
    "i = 1\n",
    "MSE_test = []\n",
    "MAE_test = []\n",
    "\n",
    "run.set_data()\n",
    "\n",
    "for multi in multi_arr:\n",
    "    print(\"\\r%d/%d\" % (i, len(multi_arr)), end=\"\")\n",
    "    Net.n_multi = multi\n",
    "    run.Net = Net.Net\n",
    "    run.fig_name1 = \"MSE of each epoch (num of multi is %.1f).png\" % multi\n",
    "    run.fig_name2 = \"MAE of each epoch (num of multi is %.1f).png\" % multi\n",
    "    run.fit()\n",
    "    run.plot()\n",
    "    test_error = run.cal_test_error()\n",
    "    MSE_test.append(test_error[0])\n",
    "    MAE_test.append(test_error[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of multi:  [1, 1.5, 2, 2.5, 3, 4]\n",
      "MSE:  [variable(493.82068), variable(229.75685), variable(335.4347), variable(222.12787), variable(299.72604), variable(299.94046)]\n",
      "MAE:  [variable(18.411568), variable(10.173277), variable(13.183862), variable(10.945747), variable(12.994248), variable(13.425252)]\n"
     ]
    }
   ],
   "source": [
    "print(\"num of multi: \", multi_arr)\n",
    "print(\"MSE: \", MSE_test)\n",
    "print(\"MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11"
     ]
    }
   ],
   "source": [
    "# https://qiita.com/ZoneTsuyoshi/items/8ef6fa1e154d176e25b8\n",
    "\n",
    "from chainer import optimizers\n",
    "\n",
    "opt_arr = [\n",
    "    optimizers.SGD(),\n",
    "    optimizers.MomentumSGD(),\n",
    "    optimizers.AdaGrad(),\n",
    "    optimizers.RMSprop(),\n",
    "    optimizers.AdaDelta(),\n",
    "    optimizers.Adam(),\n",
    "    optimizers.RMSpropGraves(),\n",
    "    optimizers.SMORMS3(),\n",
    "    optimizers.AMSGrad(),\n",
    "    optimizers.AdaBound(),\n",
    "    optimizers.AMSBound()\n",
    "]\n",
    "\n",
    "opt_name = [\n",
    "    \"SGD\",\n",
    "    \"MomentumSGD\",\n",
    "    \"AdaGrad\",\n",
    "    \"RmSprop\",\n",
    "    \"AdaDelta\",\n",
    "    \"Adam\",\n",
    "    \"RMSpropGraves\",\n",
    "    \"SMORMS3\",\n",
    "    \"AMSGrad\",\n",
    "    \"AdaBound\",\n",
    "    \"AMSBound\"\n",
    "]\n",
    "\n",
    "run = deep_learn()\n",
    "\n",
    "run.save_dir = \"fig/optimizer\"\n",
    "i = 1\n",
    "MSE_test = []\n",
    "MAE_test = []\n",
    "\n",
    "run.set_data()\n",
    "\n",
    "for opt in opt_arr:\n",
    "    print(\"\\r%d/%d\" % (i, len(opt_arr)), end=\"\")\n",
    "    run.optimizer = opt\n",
    "    run.fig_name1 = \"MSE of each epoch (optimizer is %s)\" % opt_name[i - 1]\n",
    "    run.fig_name2 = \"MAE of each epoch (optimizer is %s)\" % opt_name[i - 1]\n",
    "    run.fit()\n",
    "    run.plot()\n",
    "    test_error = run.cal_test_error()\n",
    "    MSE_test.append(test_error[0])\n",
    "    MAE_test.append(test_error[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt name:  ['SGD', 'MomentumSGD', 'AdaGrad', 'RmSprop', 'AdaDelta', 'Adam', 'RMSpropGraves', 'SMORMS3', 'AMSGrad', 'AdaBound', 'AMSBound']\n",
      "MSE:  [variable(596.67865), variable(748.88885), variable(481.1794), variable(581.58185), variable(567.9831), variable(257.87805), variable(183.6314), variable(225.72916), variable(242.25677), variable(317.26895), variable(299.14655)]\n",
      "MAE:  [variable(20.720228), variable(22.436901), variable(17.671604), variable(20.507269), variable(20.240658), variable(11.837251), variable(9.939592), variable(10.39656), variable(11.440739), variable(13.673), variable(13.514401)]\n"
     ]
    }
   ],
   "source": [
    "print(\"opt name: \", opt_name)\n",
    "print(\"MSE: \", MSE_test)\n",
    "print(\"MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5"
     ]
    }
   ],
   "source": [
    "run = deep_learn()\n",
    "\n",
    "bound_arr = [1, 2, 3, 4, 5]\n",
    "run.save_dir = \"fig/bound\"\n",
    "i = 1\n",
    "MSE_test = []\n",
    "MAE_test = []\n",
    "\n",
    "run.set_data()\n",
    "\n",
    "for bound in bound_arr:\n",
    "    print(\"\\r%d/%d\" % (i, len(bound_arr)), end=\"\")\n",
    "    run.bound = bound\n",
    "    run.fig_name1 = \"MSE of each epoch (bound is %d).png\" % bound\n",
    "    run.fig_name2 = \"MAE of each epoch (bound is %d).png\" % bound\n",
    "    run.fit()\n",
    "    run.plot()\n",
    "    test_error = run.cal_test_error()\n",
    "    MSE_test.append(test_error[0])\n",
    "    MAE_test.append(test_error[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound : [1, 2, 3, 4, 5]\n",
      "MSE:  [variable(373.4251), variable(277.93234), variable(436.827), variable(403.12445), variable(308.02844)]\n",
      "MAE:  [variable(14.932132), variable(13.277081), variable(16.416647), variable(16.157673), variable(13.493976)]\n"
     ]
    }
   ],
   "source": [
    "print(\"bound :\", bound_arr)\n",
    "print(\"MSE: \", MSE_test)\n",
    "print(\"MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = deep_learn()\n",
    "\n",
    "run.save_dir = \"fig/n_epoch\"\n",
    "\n",
    "run.set_data()\n",
    "\n",
    "run.n_epoch = 1000\n",
    "run.fig_name1 = \"MSE of each epoch (n_epohc is %d)\" % run.n_epoch\n",
    "run.fig_name2 = \"MAE of each epoch (n_epoch is %d)\" % run.n_epoch\n",
    "\n",
    "run.fit()\n",
    "run.plot()\n",
    "MSE_test, MAE_test = run.cal_test_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epoch:  1000\n",
      "MSE:  variable(671.48865)\n",
      "MAE:  variable(21.532646)\n"
     ]
    }
   ],
   "source": [
    "print(\"n_epoch: \", run.n_epoch)\n",
    "print(\"MSE: \", MSE_test)\n",
    "print(\"MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 調査ターン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3"
     ]
    }
   ],
   "source": [
    "import osero_learn as ol\n",
    "import deep_learn as dl\n",
    "\n",
    "run = dl.deep_learn()\n",
    "\n",
    "run.save_dir = \"fig/check_point\"\n",
    "\n",
    "cp_arr = [\n",
    "    [i for i in range(1, 61)],\n",
    "    [i for i in range(5, 61, 5)],\n",
    "    [i for i in range(10, 61, 10)]\n",
    "]\n",
    "cp_name = [\n",
    "    \"every 1\",\n",
    "    \"every 5\",\n",
    "    \"every 10\"\n",
    "]\n",
    "i = 1\n",
    "MSE_test = []\n",
    "MAE_test = []\n",
    "\n",
    "for cp in cp_arr:\n",
    "    print(\"\\r%d/%d\" % (i, len(cp_arr)), end=\"\")\n",
    "    run.osero = ol.learn(0, 0, check_point=cp, eva=[0, 0])\n",
    "    run.set_data()\n",
    "    run.fig_name1 = \"MSE of each epoch (turn is %s)\" % cp_name[i - 1]\n",
    "    run.fig_name2 = \"MAE of each epoch (turn is %s)\" % cp_name[i - 1]\n",
    "    run.fit()\n",
    "    run.plot()\n",
    "    test_error = run.cal_test_error()\n",
    "    MSE_test.append(test_error[0])\n",
    "    MAE_test.append(test_error[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['every 1', 'every 5', 'every 10']\n",
      "MSE:  [variable(199.15181), variable(414.1164), variable(571.50305)]\n",
      "MAE:  [variable(9.791213), variable(15.582603), variable(17.601833)]\n"
     ]
    }
   ],
   "source": [
    "print(cp_name)\n",
    "print(\"MSE: \", MSE_test)\n",
    "print(\"MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重み減衰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5"
     ]
    }
   ],
   "source": [
    "import chainer.optimizer_hooks as hf\n",
    "\n",
    "run = deep_learn()\n",
    "\n",
    "run.save_dir = \"fig/hook_function\"\n",
    "\n",
    "hf_arr = [\n",
    "    hf.WeightDecay(0.00001),\n",
    "    hf.Lasso(0.00001),\n",
    "    # hf.GradientClipping(1.0),\n",
    "    hf.GradientHardClipping(-2, 2),\n",
    "    hf.GradientNoise(0.3),\n",
    "    hf.GradientLARS()\n",
    "]\n",
    "hf_name = [\n",
    "    \"WeightDecay\",\n",
    "    \"Lasso\",\n",
    "    # \"GradientClippint\",\n",
    "    \"GradientHardClipping\",\n",
    "    \"GradientNoise\",\n",
    "    \"GradientLARS\"\n",
    "]\n",
    "i = 1\n",
    "MSE_test = []\n",
    "MAE_test = []\n",
    "\n",
    "run.set_data()\n",
    "\n",
    "for hook_f in hf_arr:\n",
    "    print(\"\\r%d/%d\" % (i, len(hf_arr)), end=\"\")\n",
    "    run.hook_f = hook_f\n",
    "    run.fig_name1 = \"MSE of each epoch (hook function is %s)\" % hf_name[i - 1]\n",
    "    run.fig_name2 = \"MAE of each epoch (hook function is %s)\" % hf_name[i - 1]\n",
    "    run.fit()\n",
    "    run.plot()\n",
    "    test_error = run.cal_test_error()\n",
    "    MSE_test.append(test_error[0])\n",
    "    MAE_test.append(test_error[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WeightDecay', 'Lasso', 'GradientHardClipping', 'GradientNoise', 'GradientLARS']\n",
      "MSE:  [variable(547.9877), variable(516.57294), variable(265.04657), variable(368.97327), variable(132.2816)]\n",
      "MAE:  [variable(19.518631), variable(19.172485), variable(11.6672735), variable(15.090247), variable(7.1252656)]\n"
     ]
    }
   ],
   "source": [
    "print(hf_name)\n",
    "print(\"MSE: \", MSE_test)\n",
    "print(\"MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientLARSの引数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.optimizer_hooks.gradient_lars import GradientLARS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## threashold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6"
     ]
    }
   ],
   "source": [
    "run = deep_learn()\n",
    "\n",
    "th_arr = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "run.save_dir = \"fig/GradientLARS/threashold\"\n",
    "i = 1\n",
    "MSE_test = []\n",
    "MAE_test = []\n",
    "\n",
    "run.set_data()\n",
    "\n",
    "for th in th_arr:\n",
    "    print(\"\\r%d/%d\" % (i, len(th_arr)), end=\"\")\n",
    "    run.hook_f = GradientLARS(threshold=th)\n",
    "    run.fig_name1 = \"MSE of each epoch (threashold is %f).png\" % th\n",
    "    run.fig_name2 = \"MAE of each epoch (threashold is %f).png\" % th\n",
    "    run.fit()\n",
    "    run.plot()\n",
    "    test_error = run.cal_test_error()\n",
    "    MSE_test.append(test_error[0])\n",
    "    MAE_test.append(test_error[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold arr:  [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
      "test MSE:  [variable(166.19632), variable(170.0784), variable(171.25908), variable(163.18517), variable(170.33223), variable(146.83133)]\n",
      "test MAE:  [variable(8.09928), variable(8.408168), variable(8.693802), variable(8.035527), variable(8.495775), variable(7.6456904)]\n"
     ]
    }
   ],
   "source": [
    "print(\"threshold arr: \", th_arr)\n",
    "print(\"test MSE: \", MSE_test)\n",
    "print(\"test MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4"
     ]
    }
   ],
   "source": [
    "run = deep_learn()\n",
    "\n",
    "wd_arr = [0.0, 0.00001, 0.0001, 0.001]\n",
    "run.save_dir = \"fig/GradientLARS/weight_decay\"\n",
    "i = 1\n",
    "MSE_test = []\n",
    "MAE_test = []\n",
    "\n",
    "run.set_data()\n",
    "\n",
    "for wd in wd_arr:\n",
    "    print(\"\\r%d/%d\" % (i, len(wd_arr)), end=\"\")\n",
    "    run.hook_f = GradientLARS(weight_decay=wd)\n",
    "    run.fig_name1 = \"MSE of each epoch (weight_decay is %f).png\" % wd\n",
    "    run.fig_name2 = \"MAE of each epoch (weight_decay is %f).png\" % wd\n",
    "    run.fit()\n",
    "    run.plot()\n",
    "    test_error = run.cal_test_error()\n",
    "    MSE_test.append(test_error[0])\n",
    "    MAE_test.append(test_error[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_decay arr:  [0.0, 1e-05, 0.0001, 0.001]\n",
      "test MSE:  [variable(150.91196), variable(148.27405), variable(147.56767), variable(157.84373)]\n",
      "test MAE:  [variable(7.587319), variable(8.179049), variable(7.731195), variable(8.590252)]\n"
     ]
    }
   ],
   "source": [
    "print(\"weight_decay arr: \", wd_arr)\n",
    "print(\"test MSE: \", MSE_test)\n",
    "print(\"test MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012340980408667962"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.e ** (-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5"
     ]
    }
   ],
   "source": [
    "run = deep_learn()\n",
    "\n",
    "eps_arr = [0.0, 0.00005, 0.0001234, 0.0002, 0.0005]\n",
    "run.save_dir = \"fig/GradientLARS/eps\"\n",
    "i = 1\n",
    "MSE_test = []\n",
    "MAE_test = []\n",
    "\n",
    "run.set_data()\n",
    "\n",
    "for eps in eps_arr:\n",
    "    print(\"\\r%d/%d\" % (i, len(eps_arr)), end=\"\")\n",
    "    run.hook_f = GradientLARS(eps=eps)\n",
    "    run.fig_name1 = \"MSE of each epoch (eps is %f).png\" % eps\n",
    "    run.fig_name2 = \"MAE of each epoch (eps is %f).png\" % eps\n",
    "    run.fit()\n",
    "    run.plot()\n",
    "    test_error = run.cal_test_error()\n",
    "    MSE_test.append(test_error[0])\n",
    "    MAE_test.append(test_error[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps arr:  [0.0, 5e-05, 0.0001234, 0.0002, 0.0005]\n",
      "test MSE:  [variable(170.8527), variable(145.1517), variable(144.97327), variable(148.69962), variable(156.80756)]\n",
      "test MAE:  [variable(8.57553), variable(7.707429), variable(7.4129925), variable(7.4839306), variable(7.969676)]\n"
     ]
    }
   ],
   "source": [
    "print(\"eps arr: \", eps_arr)\n",
    "print(\"test MSE: \", MSE_test)\n",
    "print(\"test MAE: \", MAE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = deep_learn()\n",
    "\n",
    "run.save_dir = \"fig/GradientLARS/n_epoch\"\n",
    "run.set_data()\n",
    "run.n_epoch = 1000\n",
    "\n",
    "run.hook_f = GradientLARS()\n",
    "run.fig_name1 = \"MSE of each epoch (n_epoch is %d)\" % run.n_epoch\n",
    "run.fig_name2 = \"MAE of each epoch (n_epoch is %d)\" % run.n_epoch\n",
    "run.fit()\n",
    "run.plot()\n",
    "test_error = run.cal_test_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epoch:  1000\n",
      "test MSE:  variable(574.58624)\n",
      "test MAE:  variable(20.3639)\n"
     ]
    }
   ],
   "source": [
    "print(\"n_epoch: \", run.n_epoch)\n",
    "print(\"test MSE: \", test_error[0])\n",
    "print(\"test MAE: \", test_error[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 総合実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer.optimizers as opt\n",
    "from chainer.optimizer_hooks.gradient_lars import GradientLARS\n",
    "import pandas as pd\n",
    "\n",
    "import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_arr = [150, 200, 250]\n",
    "multi_arr = [1.5, 2.0, 2.5]\n",
    "opt_arr = [\n",
    "    opt.Adam,\n",
    "    opt.RMSpropGraves,\n",
    "    opt.SMORMS3,\n",
    "    opt.AMSGrad\n",
    "]\n",
    "opt_name = [\n",
    "    \"Adam\",\n",
    "    \"RMSpropGraves\",\n",
    "    \"SMORMS3\",\n",
    "    \"AMSGrad\"\n",
    "]\n",
    "bound_arr = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data[\"batch_size\"] = []\n",
    "data[\"multi\"] = []\n",
    "data[\"optimizer\"] = []\n",
    "data[\"bound\"] = []\n",
    "data[\"test_MSE\"] = []\n",
    "data[\"test_MAE\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3......."
     ]
    }
   ],
   "source": [
    "run = deep_learn()\n",
    "run.num = 2\n",
    "run.set_data()\n",
    "i, j = 1, 1\n",
    "\n",
    "for bs in bs_arr:\n",
    "    # print(\"\\r%d/%d\" % (i, len(bs_arr)), end=\"\")\n",
    "    run.batch_size = bs\n",
    "    for multi in multi_arr:\n",
    "        print(\"\\r%d/%d\" % (i, len(bs_arr)) + \".\" * j, end=\"\")\n",
    "        # print(\".\", end=\"\")\n",
    "        Net.n_multi = multi\n",
    "        run.Net = Net.Net\n",
    "        for opt_num in range(len(opt_arr)):\n",
    "            run.optimizer = opt_arr[opt_num]()\n",
    "            for bound in bound_arr:\n",
    "                run.bound = bound\n",
    "                run.hook_f = GradientLARS()\n",
    "                run.fit()\n",
    "                test_error = run.cal_test_error()\n",
    "                data[\"batch_size\"].append(bs)\n",
    "                data[\"multi\"].append(multi)\n",
    "                data[\"optimizer\"].append(opt_name[opt_num])\n",
    "                data[\"bound\"].append(bound)\n",
    "                data[\"test_MSE\"].append(test_error[0])\n",
    "                data[\"test_MAE\"].append(test_error[1])\n",
    "        \n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "data_df.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "400b3448902b2aa85e7a3848e7bd72dda1a711f8af9f184efc41490bde870126"
  },
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
